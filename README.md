## Adversarial attack Sirius and Yandex workshop project

An attack on image classifiers introduces unpredictable behavior for many computer vision systems. The goal of this project is to investigate a new type of attack, in which completely different images have the same representation in the neurogenic network.

### References

- [Excessive Invariance Causes Adversarial Vulnerability](https://arxiv.org/pdf/1811.00401.pdf)

### Dataset

- MNIST&ImageNet

### Authors

- [Alex Babushkin](https://github.com/ocelaiwo)
- [Diana Zagidullina](https://github.com/dianazagidullina)
- [Dmitry Kalinin](https://github.com/ActiveChooN)
